{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle_Report\n",
    "*by Francis Wobulu Wesa*\n",
    "\n",
    "## Indtoduction\n",
    "Thi project helped me put in practice what i had learned in my Data Wrangling class.The\tdataset used is\tthe\ttweet archive of Twitter user @dog_rates, also known as WeRateDogs.\tWeRateDogs is a\tTwitter\taccount\tthat rates people's dogs.\n",
    "This report\tdecribes my\twrangling\tefforts.\t\t\n",
    "\n",
    "**Tasks Undertaken**\n",
    "- Gathering Data\n",
    "- Accessing Data\n",
    "- cleaning Data\n",
    "\n",
    "### Gathering Data.\n",
    "This step involved obtaining three dataset from diffrent sources and loading them into a pandas data frame for use\n",
    "- **Twitter archive file**:- twitter_archive_enhanced.csv was provided by udacity, i donwnlaoded it then uploaded it manually ono the jupiter notebook working space whereby i was able load and read it using pandas\n",
    "- **Tweet image\tpredictions**:-This\tfile (image_predictions.tsv) is\thosted\ton Udacity's servers and was downloaded\tprogrammatically using the Requests\tlibrary\tand\tURL\tinformation\n",
    "- **Twitter\tAPI\t& JSON**:- I was able to download the tweetjson.txt file programmatically using the Request libray and the url provided and was able to extract impotart data, retweet count and favorite count bases on tweet_id.\n",
    "\n",
    "### Accessing Data\n",
    "Once allthe data was obtained and load into tables using pandas dataframe tools, it was time for assesment.i used two metthods to access the data.\n",
    "- **Visual Accessment**:- I visually assesed the data by loading the data frames in jupyter notebook and looking through the data for any tidy and cleanliness issues.\n",
    "- **Programmatical Accessment**:- i used diffrent methods available like;- info(), value_counts(), duplicated() and many more to root out the tidyness issues and dirt present in my datasets.\\\n",
    "\n",
    "### Cleanind Data\n",
    "After accessing my data both visually and programmatically, i listed doen the cleanliness and tidyness issues down so that my cleaning process can be guided and made much simpler since i know the issues to be tackled.\n",
    "These were the cleaning issues tackled.\n",
    "\n",
    "1.Only intrested in original tweets thus have to remove retweets that contain @RT\n",
    "\n",
    "2.Missing values in `in_reply_to_status_id`, `in_reply_to_user_id`, `retweeted_status_id`, `retweeted_status_user_id`,`retweeted_status_timestamp`\n",
    "\n",
    "3.Timestamp is an object data type, it should be datetime.\n",
    "\n",
    "4.on twitter archive in the name column, None appears instead of NaN value\n",
    "\n",
    "5.Text of the tweet is not visible, it can be used to give additional info\n",
    "\n",
    "\n",
    "6.Drop the rating_denominator column and only use the rating_numerator column out of 10\n",
    "\n",
    "7.We have dulpicates in image prediction under jpg_url\n",
    "\n",
    "8.Inconsitent data in p1, p2, p3 columns some are in uppercase while some are in lower case\n",
    "\n",
    "\n",
    "\n",
    "These were the tidiness issues tackled \n",
    "\n",
    "1.keep only one prediction of dog breed with its confidence level\n",
    "\n",
    "2.the dog stage is one variable and hence should form single column. But this variable is spread across 4 columns - doggo, floofer, pupper, puppo\n",
    "\n",
    "3.`twitter archive`,`image_prediction` and `tweet_json` all the data belongs to one table because they are all characteristics of the tweets\n",
    "\n",
    "All this were done in three steps.\n",
    "1. Define\n",
    "2. Code\n",
    "3. Test\n",
    "\n",
    "i had to define the issue i was cleaning up, the code written to finally carry out the cleaning task and lastly i had to test to make sure the data was clean.\n",
    "\n",
    "### Analyzing and Visualization\n",
    "lastly i had to carry out a few analysis on the clean data and create a couple of visualization to support my analysis.\n",
    "\n",
    "### Conclusion\n",
    "Data warngling is a key step in the data analysis process. one should be familiar with the necessary tools and procedures used to gatther, accesses and clean data for efficient analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
